{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import rdkit.Chem as Chem\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28317\\AppData\\Local\\Temp\\ipykernel_28952\\1803978.py:8: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dt = pd.read_csv(path).iloc[:, :3]\n"
     ]
    }
   ],
   "source": [
    "filePath = '../../../xtb_ml_data' # 提取全部的data，以及sensitizer和emitter\n",
    "xtb_data = os.listdir(filePath)\n",
    "dt_list = []\n",
    "\n",
    "j = 0\n",
    "for i in xtb_data:\n",
    "    path = filePath + \"/\" + i\n",
    "    dt = pd.read_csv(path).iloc[:, :3]\n",
    "    dt.columns = ['SMILES', 'xTB_S1', 'xTB_T1']\n",
    "    dt = dt[~dt['xTB_S1'].isin(['Invalid SMILES'])]\n",
    "    dt['T1S1ratio'] = pd.to_numeric(dt['xTB_T1']) / pd.to_numeric(dt['xTB_S1'])\n",
    "    dt_list.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部数据合并\n",
    "dt_tot = pd.concat(dt_list)  \n",
    "dt_tot = dt_tot.drop_duplicates(subset = 'SMILES', keep=False)\n",
    "dt_tot.dropna(inplace = True)\n",
    "dt_tot.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17667/684444 [00:01<01:05, 10177.28it/s][15:18:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:18:47] WARNING: not removing hydrogen atom without neighbors\n",
      "  3%|▎         | 22747/684444 [00:02<01:06, 9988.47it/s] [15:18:47] WARNING: not removing hydrogen atom without neighbors\n",
      "  4%|▍         | 25831/684444 [00:02<01:06, 9954.76it/s] [15:18:48] WARNING: not removing hydrogen atom without neighbors\n",
      "  6%|▌         | 41011/684444 [00:04<01:03, 10172.93it/s][15:18:49] WARNING: not removing hydrogen atom without neighbors\n",
      "  6%|▌         | 42055/684444 [00:04<01:02, 10242.70it/s][15:18:49] WARNING: not removing hydrogen atom without neighbors\n",
      " 31%|███▏      | 214311/684444 [00:37<01:54, 4117.41it/s][15:19:23] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      " 70%|███████   | 480194/684444 [01:25<01:28, 2299.16it/s] [15:20:10] WARNING: not removing hydrogen atom without neighbors\n",
      " 71%|███████   | 482872/684444 [01:26<01:15, 2685.63it/s][15:20:11] WARNING: not removing hydrogen atom without neighbors\n",
      " 73%|███████▎  | 496477/684444 [01:31<01:13, 2561.34it/s][15:20:16] WARNING: not removing hydrogen atom without neighbors\n",
      " 73%|███████▎  | 498727/684444 [01:32<01:07, 2757.54it/s][15:20:17] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      " 85%|████████▌ | 583101/684444 [02:04<00:35, 2818.37it/s][15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      " 85%|████████▌ | 583871/684444 [02:04<00:23, 4263.21it/s][15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      " 86%|████████▌ | 585340/684444 [02:04<00:13, 7343.58it/s][15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      " 86%|████████▌ | 586775/684444 [02:04<00:10, 9409.79it/s][15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      " 86%|████████▋ | 590977/684444 [02:05<00:07, 12487.48it/s][15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      " 87%|████████▋ | 592619/684444 [02:05<00:06, 13632.92it/s][15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:50] WARNING: not removing hydrogen atom without neighbors\n",
      " 87%|████████▋ | 596720/684444 [02:05<00:06, 12847.13it/s][15:20:51] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:51] WARNING: not removing hydrogen atom without neighbors\n",
      " 88%|████████▊ | 600547/684444 [02:05<00:06, 12233.72it/s][15:20:51] WARNING: not removing hydrogen atom without neighbors\n",
      " 88%|████████▊ | 601775/684444 [02:05<00:06, 11990.21it/s][15:20:51] WARNING: not removing hydrogen atom without neighbors\n",
      " 88%|████████▊ | 602982/684444 [02:06<00:06, 11993.04it/s][15:20:51] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:51] WARNING: not removing hydrogen atom without neighbors\n",
      " 91%|█████████ | 620150/684444 [02:07<00:06, 9522.46it/s] [15:20:53] WARNING: not removing hydrogen atom without neighbors\n",
      " 93%|█████████▎| 634684/684444 [02:09<00:05, 9509.93it/s][15:20:54] WARNING: not removing hydrogen atom without neighbors\n",
      " 93%|█████████▎| 636634/684444 [02:09<00:05, 9511.36it/s][15:20:55] WARNING: not removing hydrogen atom without neighbors\n",
      " 94%|█████████▎| 641331/684444 [02:10<00:04, 9184.33it/s][15:20:55] WARNING: not removing hydrogen atom without neighbors\n",
      " 94%|█████████▍| 645082/684444 [02:10<00:04, 8780.12it/s][15:20:56] WARNING: not removing hydrogen atom without neighbors\n",
      " 95%|█████████▍| 646950/684444 [02:10<00:04, 9046.79it/s][15:20:56] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|█████████▌| 655539/684444 [02:11<00:03, 9596.28it/s][15:20:57] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|█████████▌| 657609/684444 [02:11<00:02, 9936.70it/s][15:20:57] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|█████████▌| 658687/684444 [02:12<00:02, 10162.43it/s][15:20:57] WARNING: not removing hydrogen atom without neighbors\n",
      " 96%|█████████▋| 659764/684444 [02:12<00:02, 10325.43it/s][15:20:57] WARNING: not removing hydrogen atom without neighbors\n",
      " 97%|█████████▋| 660797/684444 [02:12<00:02, 10198.26it/s][15:20:57] WARNING: not removing hydrogen atom without neighbors\n",
      " 97%|█████████▋| 662845/684444 [02:12<00:02, 9673.98it/s] [15:20:57] WARNING: not removing hydrogen atom without neighbors\n",
      " 97%|█████████▋| 663819/684444 [02:12<00:02, 9475.07it/s][15:20:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:57] WARNING: not removing hydrogen atom without neighbors\n",
      " 97%|█████████▋| 665803/684444 [02:12<00:01, 9663.57it/s][15:20:58] WARNING: not removing hydrogen atom without neighbors\n",
      " 98%|█████████▊| 669863/684444 [02:13<00:01, 9727.61it/s][15:20:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:58] WARNING: not removing hydrogen atom without neighbors\n",
      " 98%|█████████▊| 671801/684444 [02:13<00:01, 9616.61it/s][15:20:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:58] WARNING: not removing hydrogen atom without neighbors\n",
      " 99%|█████████▉| 679928/684444 [02:14<00:00, 10125.64it/s][15:20:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:20:59] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|█████████▉| 683016/684444 [02:14<00:00, 9789.84it/s] [15:21:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:21:00] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|██████████| 684444/684444 [02:14<00:00, 5083.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# 去掉全部带电的分子\n",
    "index = []\n",
    "for i in tqdm(range(len(dt_tot))):\n",
    "    mol = Chem.MolFromSmiles(dt_tot.iloc[i, 0])\n",
    "    if mol == None: \n",
    "        continue\n",
    "    Chem.Kekulize(mol)\n",
    "    if abs(Chem.GetFormalCharge(mol)) == 0:\n",
    "        index.append(i)\n",
    "\n",
    "dt_tot = dt_tot.iloc[index, :]\n",
    "dt_tot.reset_index(drop = True, inplace = True)\n",
    "dt_emit = dt_tot[(dt_tot['T1S1ratio'] > (1/2.2)) & (dt_tot['T1S1ratio'] < (1/1.8))]\n",
    "dt_sens = dt_tot[(dt_tot['T1S1ratio'] > 0.8) & (dt_tot['T1S1ratio'] < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分测试集\n",
    "np.random.seed(2022)\n",
    "def is_large(smi): # split the target data according to atom_num > 20\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    atoms_num = mol.GetNumAtoms()\n",
    "    if atoms_num > 20:\n",
    "        return True\n",
    "    if atoms_num <= 20:\n",
    "        return False\n",
    "\n",
    "test_rand = dt_tot.sample(n = 3000, replace = False)\n",
    "test_emit = dt_emit.sample(n = 3000, replace = False)\n",
    "test_sens = dt_sens.sample(n = 3000, replace = False)\n",
    "test_tot = pd.concat([test_rand, test_emit, test_sens])  \n",
    "test_tot = test_tot.drop_duplicates(subset = 'SMILES', keep=False)\n",
    "test_tot['is_large'] = test_tot['SMILES'].apply(lambda x: is_large(x))\n",
    "test_large = test_tot[test_tot['is_large'] == True]\n",
    "test_small = test_tot[test_tot['is_large'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rand.to_csv('../test_set/test_rand.csv')\n",
    "test_emit.to_csv('../test_set/test_emit.csv')\n",
    "test_sens.to_csv('../test_set/test_sens.csv')\n",
    "test_large.to_csv('../test_set/test_large.csv')\n",
    "test_small.to_csv('../test_set/test_small.csv')\n",
    "test_tot.to_csv('../test_set/test_tot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tot_dup = pd.concat([test_tot.iloc[:, :-1], dt_tot])\n",
    "dt_tot = dt_tot_dup.drop_duplicates(subset = 'SMILES', keep=False)\n",
    "dt_tot.reset_index(drop = True, inplace = True)\n",
    "dt_train = dt_tot.sample(n = 5000, replace = False, random_state=2022)\n",
    "dt_train.to_csv('init_train.csv') # 第一轮训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tot_round1 = pd.concat([dt_train, dt_tot])\n",
    "dt_tot_round1 = dt_tot_round1.drop_duplicates(subset = 'SMILES', keep = False)\n",
    "dt_tot_round1.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tot_round1.to_csv('../data_tot/dt_tot_round1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_and_pred(dt_tot_csv, cut_len, round, check_point_path):\n",
    "    import math\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import time\n",
    "\n",
    "    os.mkdir(f'../cut_data/origin_cut/round_{round}')\n",
    "    os.mkdir(f'../cut_data/pred_cut/round_{round}')\n",
    "\n",
    "    dt_tot = pd.read_csv(dt_tot_csv)\n",
    "    dt_tot.reset_index(drop = True, inplace = True)\n",
    "    tot_len = len(dt_tot)\n",
    "    file_num = math.ceil(tot_len / cut_len)\n",
    "    for i in range(file_num):\n",
    "        if i != (file_num - 1):\n",
    "            dt_tot.iloc[i*cut_len:(i+1)*cut_len, :].to_csv(f'../cut_data/origin_cut/round_{round}/dt_tot_{i}.csv')\n",
    "        if i == (file_num - 1):\n",
    "            dt_tot.iloc[i*cut_len:, :].to_csv(f'../cut_data/origin_cut/round_{round}/dt_tot_{i}.csv')\n",
    "    for i in range(file_num):\n",
    "        print(i)\n",
    "        test_path = f'../cut_data/origin_cut/round_{round}/dt_tot_{i}.csv'\n",
    "        pred_path = f'../cut_data/pred_cut/round_{round}/dt_tot_{i}.csv'\n",
    "        pred = f'dt_tot_{i}.csv'\n",
    "        k = 0\n",
    "        while pred not in os.listdir(f'../cut_data/pred_cut/round_{round}'):\n",
    "            os.system(f'chemprop_predict --test_path {test_path} --checkpoint_dir {check_point_path} --preds_path {pred_path} --smiles_column SMILES --ensemble_variance --num_workers 0')\n",
    "            time.sleep(10)\n",
    "            if k >= 1:\n",
    "                print(f'data{i} fail {k} time(s)')\n",
    "            k = k + 1\n",
    "            \n",
    "    dt_list = []\n",
    "    for i in range(file_num):\n",
    "        dt_path = f'../cut_data/pred_cut/round_{round}/dt_tot_{i}.csv'\n",
    "        dt = pd.read_csv(dt_path)\n",
    "        dt_list.append(dt)\n",
    "    pred_tot = pd.concat(dt_list).dropna()\n",
    "    pred_tot.reset_index(drop = True, inplace = True)\n",
    "    pred_tot = pred_tot[~pred_tot['xTB_S1'].isin(['Invalid SMILES'])]\n",
    "    pred_tot['uncertainty_tot'] = pred_tot['xTB_S1_epi_unc'].apply(lambda x: float(x)) + pred_tot['xTB_T1_epi_unc'].apply(lambda x: float(x))\n",
    "    pred_tot.sort_values(by = 'uncertainty_tot', ascending = False, inplace = True)\n",
    "    pred_index = pred_tot.index[:20000]\n",
    "    \n",
    "    newtrain = dt_tot.iloc[pred_index, :]\n",
    "    train_set = pd.read_csv(f'../train_set/train_round{round}.csv')\n",
    "    train_set = pd.concat([newtrain, train_set])\n",
    "    train_set.to_csv(f'../train_set/train_round{round+1}.csv')\n",
    "\n",
    "    dt_tot_new = dt_tot.iloc[list(set(pred_tot.index)-set(pred_index)), :]\n",
    "    dt_tot_new.reset_index(drop = True, inplace = True)\n",
    "    dt_tot_new.to_csv(f'../data_tot/dt_tot_round{round+1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_and_pred_diversity(dt_tot_csv, cut_len, round, check_point_path):\n",
    "    import math\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    import rdkit.Chem as Chem\n",
    "    from rdkit.Chem import AllChem\n",
    "    from rdkit import DataStructs\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    os.mkdir(f'../batch_version/cut_data/origin_cut/round_{round}')\n",
    "    os.mkdir(f'../batch_version/cut_data/pred_cut/round_{round}')\n",
    "\n",
    "    dt_tot = pd.read_csv(dt_tot_csv)\n",
    "    dt_tot.reset_index(drop = True, inplace = True)\n",
    "    tot_len = len(dt_tot)\n",
    "    file_num = math.ceil(tot_len / cut_len)\n",
    "    for i in range(file_num):\n",
    "        if i != (file_num - 1):\n",
    "            dt_tot.iloc[i*cut_len:(i+1)*cut_len, :].to_csv(f'../batch_version/cut_data/origin_cut/round_{round}/dt_tot_{i}.csv')\n",
    "        if i == (file_num - 1):\n",
    "            dt_tot.iloc[i*cut_len:, :].to_csv(f'../batch_version/cut_data/origin_cut/round_{round}/dt_tot_{i}.csv')\n",
    "    for i in range(file_num):\n",
    "        print(i)\n",
    "        test_path = f'../batch_version/cut_data/origin_cut/round_{round}/dt_tot_{i}.csv'\n",
    "        pred_path = f'../batch_version/cut_data/pred_cut/round_{round}/dt_tot_{i}.csv'\n",
    "        pred = f'dt_tot_{i}.csv'\n",
    "        k = 0\n",
    "        while pred not in os.listdir(f'../batch_version/cut_data/pred_cut/round_{round}'):\n",
    "            os.system(f'chemprop_predict --test_path {test_path} --checkpoint_dir {check_point_path} --preds_path {pred_path} --smiles_column SMILES --ensemble_variance --num_workers 0')\n",
    "            time.sleep(10)\n",
    "            if k >= 1:\n",
    "                print(f'data{i} fail {k} time(s)')\n",
    "            k = k + 1\n",
    "            \n",
    "    dt_list = []\n",
    "    for i in range(file_num):\n",
    "        dt_path = f'../batch_version/cut_data/pred_cut/round_{round}/dt_tot_{i}.csv'\n",
    "        dt = pd.read_csv(dt_path)\n",
    "        dt_list.append(dt)\n",
    "    pred_tot = pd.concat(dt_list).dropna()\n",
    "    pred_tot.reset_index(drop = True, inplace = True)\n",
    "    pred_tot = pred_tot[~pred_tot['xTB_S1'].isin(['Invalid SMILES'])]\n",
    "    pred_tot['uncertainty_tot'] = pred_tot['xTB_S1_epi_unc'].apply(lambda x: float(x)) + pred_tot['xTB_T1_epi_unc'].apply(lambda x: float(x))\n",
    "    pred_tot.sort_values(by = 'uncertainty_tot', ascending = False, inplace = True)\n",
    "\n",
    "    suggest_list = []\n",
    "    total_fingerprint = []\n",
    "    pred_len = len(pred_tot)\n",
    "    loop = 0\n",
    "    similar_value_threshold = 0.4\n",
    "    similar_num_threshold = 5\n",
    "\n",
    "    total_smiles = pred_tot['SMILES'][0:20000]\n",
    "    for smile in tqdm(total_smiles):\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        fingerprint = AllChem.GetMorganFingerprint(mol)\n",
    "        total_fingerprint.append(fingerprint)\n",
    "\n",
    "    for i in tqdm(range(20000)):\n",
    "        suggest_list.append(i)\n",
    "        k = 0\n",
    "        loop += 1\n",
    "        query_fingerprint = total_fingerprint[i]\n",
    "        if i >= 10:\n",
    "            target_fingerprints = total_fingerprint[0:i]\n",
    "            scores = DataStructs.BulkTanimotoSimilarity(query_fingerprint, target_fingerprints)\n",
    "            total_similar_num = len(list(filter(lambda x: x > similar_value_threshold, scores)))\n",
    "            if total_similar_num > similar_num_threshold:\n",
    "                suggest_list.pop()\n",
    "    \n",
    "    if len(suggest_list) < 20000:\n",
    "        for i in tqdm(range(20000, pred_len)):\n",
    "            new_smile = pred_tot['SMILES'][i]\n",
    "            new_mol = Chem.MolFromSmiles(new_smile)\n",
    "            new_fingerprint = AllChem.GetMorganFingerprint(new_mol,2)\n",
    "            total_fingerprint.append(new_fingerprint)\n",
    "            suggest_list.append(i)\n",
    "            query_fingerprint = total_fingerprint[i]\n",
    "            target_fingerprints = total_fingerprint[0:i]\n",
    "            scores = DataStructs.BulkTanimotoSimilarity(query_fingerprint, target_fingerprints)\n",
    "            total_similar_num = len(list(filter(lambda x: x > similar_value_threshold, scores)))\n",
    "            if total_similar_num > similar_num_threshold:\n",
    "                suggest_list.pop()\n",
    "            if len(suggest_list) >= 20000:\n",
    "                break\n",
    "\n",
    "    pred_index = pred_tot.index[suggest_list]\n",
    "    newtrain = dt_tot.iloc[pred_index, :]\n",
    "    train_set = pd.read_csv(f'../batch_version/train_set/train_round{round}.csv')\n",
    "    train_set = pd.concat([newtrain, train_set])\n",
    "    train_set.to_csv(f'../batch_version/train_set/train_round{round+1}.csv')\n",
    "\n",
    "    dt_tot_new = dt_tot.iloc[list(set(pred_tot.index)-set(pred_index)), :]\n",
    "    dt_tot_new.reset_index(drop = True, inplace = True)\n",
    "    dt_tot_new.to_csv(f'../batch_version/data_tot/dt_tot_round{round+1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "data0 fail 1 time(s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\李佳礼项目\\code\\data_manipulate.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%9D%8E%E4%BD%B3%E7%A4%BC%E9%A1%B9%E7%9B%AE/code/data_manipulate.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwhile\u001b[39;00m pred \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../batch_version/cut_data/pred_cut/round_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9D%8E%E4%BD%B3%E7%A4%BC%E9%A1%B9%E7%9B%AE/code/data_manipulate.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     os\u001b[39m.\u001b[39msystem(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mchemprop_predict --test_path \u001b[39m\u001b[39m{\u001b[39;00mtest_path\u001b[39m}\u001b[39;00m\u001b[39m --checkpoint_dir \u001b[39m\u001b[39m{\u001b[39;00mcheck_point_path\u001b[39m}\u001b[39;00m\u001b[39m --preds_path \u001b[39m\u001b[39m{\u001b[39;00mpred_path\u001b[39m}\u001b[39;00m\u001b[39m --smiles_column SMILES --ensemble_variance --num_workers 0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E6%9D%8E%E4%BD%B3%E7%A4%BC%E9%A1%B9%E7%9B%AE/code/data_manipulate.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9D%8E%E4%BD%B3%E7%A4%BC%E9%A1%B9%E7%9B%AE/code/data_manipulate.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%9D%8E%E4%BD%B3%E7%A4%BC%E9%A1%B9%E7%9B%AE/code/data_manipulate.ipynb#X40sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m fail \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m time(s)\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "check_point_path = '../batch_version/model/round_2'\n",
    "round = 2\n",
    "for i in range(19):\n",
    "    print(i)\n",
    "    test_path = f'../batch_version/cut_data/origin_cut/round_2/dt_tot_{i}.csv'\n",
    "    pred_path = f'../batch_version/cut_data/pred_cut/round_2/dt_tot_{i}.csv'\n",
    "    k = 0\n",
    "    pred = f'dt_tot_{i}.csv'\n",
    "    while pred not in os.listdir(f'../batch_version/cut_data/pred_cut/round_{round}'):\n",
    "        os.system(f'chemprop_predict --test_path {test_path} --checkpoint_dir {check_point_path} --preds_path {pred_path} --smiles_column SMILES --ensemble_variance --num_workers 0')\n",
    "        time.sleep(10)\n",
    "        if k >= 1:\n",
    "            print(f'data{i} fail {k} time(s)')\n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:03<00:00, 5308.44it/s]\n",
      "100%|██████████| 20000/20000 [02:30<00:00, 133.19it/s]\n",
      "  1%|          | 6376/527917 [01:54<2:36:26, 55.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dt_list = []\n",
    "round = 2\n",
    "dt_tot = pd.read_csv('../batch_version/data_tot/dt_tot_round2.csv')\n",
    "dt_tot.reset_index(drop = True, inplace = True)\n",
    "for i in range(19):\n",
    "    dt_path = f'../batch_version/cut_data/pred_cut/round_{round}/dt_tot_{i}.csv'\n",
    "    dt = pd.read_csv(dt_path)\n",
    "    dt_list.append(dt)\n",
    "pred_tot = pd.concat(dt_list).dropna()\n",
    "pred_tot.reset_index(drop = True, inplace = True)\n",
    "pred_tot = pred_tot[~pred_tot['xTB_S1'].isin(['Invalid SMILES'])]\n",
    "pred_tot['uncertainty_tot'] = pred_tot['xTB_S1_epi_unc'].apply(lambda x: float(x)) + pred_tot['xTB_T1_epi_unc'].apply(lambda x: float(x))\n",
    "pred_tot.sort_values(by = 'uncertainty_tot', ascending = False, inplace = True)\n",
    "\n",
    "suggest_list = []\n",
    "total_fingerprint = []\n",
    "pred_len = len(pred_tot)\n",
    "loop = 0\n",
    "similar_value_threshold = 0.4\n",
    "similar_num_threshold = 5\n",
    "\n",
    "total_smiles = pred_tot['SMILES'][0:20000]\n",
    "for smile in tqdm(total_smiles):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    fingerprint = AllChem.GetMorganFingerprint(mol, 2)\n",
    "    total_fingerprint.append(fingerprint)\n",
    "\n",
    "for i in tqdm(range(20000)):\n",
    "    suggest_list.append(i)\n",
    "    k = 0\n",
    "    loop += 1\n",
    "    query_fingerprint = total_fingerprint[i]\n",
    "    if i >= 10:\n",
    "        target_fingerprints = total_fingerprint[0:i]\n",
    "        scores = DataStructs.BulkTanimotoSimilarity(query_fingerprint, target_fingerprints)\n",
    "        total_similar_num = len(list(filter(lambda x: x > similar_value_threshold, scores)))\n",
    "        if total_similar_num > similar_num_threshold:\n",
    "            suggest_list.pop()\n",
    "\n",
    "if len(suggest_list) < 20000:\n",
    "    for i in tqdm(range(20000, pred_len)):\n",
    "        new_smile = pred_tot['SMILES'][i]\n",
    "        new_mol = Chem.MolFromSmiles(new_smile)\n",
    "        new_fingerprint = AllChem.GetMorganFingerprint(new_mol,2)\n",
    "        total_fingerprint.append(new_fingerprint)\n",
    "        suggest_list.append(i)\n",
    "        query_fingerprint = total_fingerprint[i]\n",
    "        target_fingerprints = total_fingerprint[0:i]\n",
    "        scores = DataStructs.BulkTanimotoSimilarity(query_fingerprint, target_fingerprints)\n",
    "        total_similar_num = len(list(filter(lambda x: x > similar_value_threshold, scores)))\n",
    "        if total_similar_num > similar_num_threshold:\n",
    "            suggest_list.pop()\n",
    "        if len(suggest_list) >= 20000:\n",
    "            break\n",
    "\n",
    "pred_index = pred_tot.index[suggest_list]\n",
    "newtrain = dt_tot.iloc[pred_index, :]\n",
    "train_set = pd.read_csv(f'../batch_version/train_set/train_round{round}.csv')\n",
    "train_set = pd.concat([newtrain, train_set])\n",
    "train_set.to_csv(f'../batch_version/train_set/train_round{round+1}.csv')\n",
    "\n",
    "dt_tot_new = dt_tot.iloc[list(set(pred_tot.index)-set(pred_index)), :]\n",
    "dt_tot_new.reset_index(drop = True, inplace = True)\n",
    "dt_tot_new.to_csv(f'../batch_version/data_tot/dt_tot_round{round+1}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "tot_csv = '../data_tot/dt_tot_round7.csv'\n",
    "check_path = '../model/round_7'\n",
    "cut_and_pred(tot_csv, 30000, 7, check_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do:\n",
    "- ~~把测试集输出成csv文件整理好~~\n",
    "- ~~修改cut_and_pred函数，把输入参数设定为csv，以及简单格式~~\n",
    "- ~~把后续的pred和uncertainty排序整合进原有的cut_and_pred中，使其返回csv格式文件~~\n",
    "- ~~编写好test脚本，计算针对不同test set的四个评价指标：MAE, RMSE, R^2, spearman correlation~~\n",
    "- 整理train代码，并封装至脚本中\n",
    "- 把train和cut_and_pred整合在一起\n",
    "- 把全流程整合在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_index(round, check_point_path):\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    filePath = '../test_set' \n",
    "    os.mkdir(f'../pred_set/round_{round}')\n",
    "    test_csv = os.listdir(filePath)\n",
    "    test_result_list = []\n",
    "\n",
    "    for i in test_csv:\n",
    "        test_path = filePath + '/' + i\n",
    "        test_set = pd.read_csv(test_path)\n",
    "        pred_path = f'../pred_set/round_{round}/{i}'\n",
    "        os.system(f'chemprop_predict --test_path {test_path} --checkpoint_dir {check_point_path} --preds_path {pred_path} --smiles_column SMILES --ensemble_variance --num_workers 0')\n",
    "        \n",
    "        pred_set = pd.read_csv(pred_path).dropna()\n",
    "        pred_set.reset_index(drop = True, inplace = True)\n",
    "        pred_set = pred_set[~pred_set['xTB_S1'].isin(['Invalid SMILES'])]\n",
    "        S1_uncertainty = pred_set['xTB_S1_epi_unc'].apply(lambda x: float(x))\n",
    "        T1_uncertainty = pred_set['xTB_T1_epi_unc'].apply(lambda x: float(x))\n",
    "\n",
    "        # calculate\n",
    "        S1_error = abs(test_set['xTB_S1'] - pred_set['xTB_S1'])\n",
    "        T1_error = abs(test_set['xTB_T1'] - pred_set['xTB_T1'])\n",
    "        S1_spearman_correlation = S1_uncertainty.corr(S1_error,'spearman')\n",
    "        T1_spearman_correlation = T1_uncertainty.corr(T1_error,'spearman')\n",
    "        S1_pearson_correlation = S1_uncertainty.corr(S1_error,'pearson')\n",
    "        T1_pearson_correlation = T1_uncertainty.corr(T1_error,'pearson')\n",
    "        S1_mae = S1_error.mean()\n",
    "        T1_mae = T1_error.mean()\n",
    "        S1_rmse = ((S1_error*S1_error).mean()) ** 0.5\n",
    "        T1_rmse = ((T1_error*T1_error).mean()) ** 0.5\n",
    "\n",
    "        # store the result in dictionary\n",
    "        test_dict = {'File_name' : i, 'S1_spearman_correlation' : S1_spearman_correlation, \n",
    "        'T1_spearman_correlation' : T1_spearman_correlation, 'S1_pearson_correlation' : S1_pearson_correlation,\n",
    "        'T1_pearson_correlation' : T1_pearson_correlation, 'S1_mae' : S1_mae, 'T1_mae' : T1_mae, 'S1_rmse' : S1_rmse, 'T1_rmse' : T1_rmse}\n",
    "        test_result_list.append(test_dict)\n",
    "\n",
    "    store_path = f'../test_performance/test_round{round}.csv'\n",
    "    pd.DataFrame(test_result_list).to_csv(store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index(8, '../model/round_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index(2, '../model/round_2')\n",
    "test_index(3, '../batch_version/model/round_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487906\n",
      "100000\n",
      "587906\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv('../data_tot/dt_tot_round5.csv')\n",
    "print(len(a))\n",
    "b = pd.read_csv('../train_set/train_round5.csv')\n",
    "print(len(b))\n",
    "c = pd.concat([a, b]).drop_duplicates(subset = 'SMILES', keep = False)\n",
    "print(len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_list = []\n",
    "for i in range(10):\n",
    "    dt_path = f'../cut_data/pred_cut/round_1/round1pred_{i}.csv'\n",
    "    dt = pd.read_csv(dt_path)\n",
    "    dt_list.append(dt)\n",
    "pred_tot = pd.concat(dt_list).dropna()\n",
    "pred_tot.reset_index(drop = True, inplace = True)\n",
    "pred_tot = pred_tot[~pred_tot['xTB_S1'].isin(['Invalid SMILES'])]\n",
    "pred_tot['uncertainty_tot'] = pred_tot['xTB_S1_epi_unc'].apply(lambda x: float(x)) + pred_tot['xTB_T1_epi_unc'].apply(lambda x: float(x))\n",
    "pred_tot.sort_values(by = 'uncertainty_tot', ascending = False, inplace = True)\n",
    "#pred_tot.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_list = []\n",
    "for i in range(10):\n",
    "    dt_path = f'../cut_data/origin_cut/round_1/round1dt_tot_{i}.csv'\n",
    "    dt = pd.read_csv(dt_path)\n",
    "    dt_list.append(dt)\n",
    "origin_tot = pd.concat(dt_list).dropna()\n",
    "origin_tot.reset_index(drop = True, inplace = True)\n",
    "#pred_tot.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggest_list = []\n",
    "pred_len = len(pred_tot)\n",
    "loop = 0\n",
    "\n",
    "for i in range(pred_len):\n",
    "    suggest_list.append(i)\n",
    "    k = 0\n",
    "    loop = loop + 1\n",
    "    smile_target = pred_tot.loc[i, 'SMILES']\n",
    "    m_target = Chem.MolFromSmiles(smile_target)\n",
    "    fp_target = AllChem.GetMorganFingerprint(m_target, 2)\n",
    "    if i >= 10:\n",
    "        for j in range(i):\n",
    "            smile_move = pred_tot.loc[j, 'SMILES']\n",
    "            m_move = Chem.MolFromSmiles(smile_move)\n",
    "            fp_move = AllChem.GetMorganFingerprint(m_move, 2)\n",
    "            similarity = DataStructs.DiceSimilarity(fp_target, fp_move)\n",
    "            if similarity > 0.5:\n",
    "                k = k + 1\n",
    "            if k >= 10:\n",
    "                suggest_list.pop()\n",
    "                break\n",
    "    if len(suggest_list) >= 20000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:03<00:00, 6191.90it/s]\n",
      "100%|██████████| 20000/20000 [01:53<00:00, 176.37it/s]\n"
     ]
    }
   ],
   "source": [
    "suggest_list = []\n",
    "total_fingerprint = []\n",
    "pred_len = len(pred_tot)\n",
    "#loop = 0\n",
    "similar_value_threshold = 0.5\n",
    "similar_num_threshold = 10\n",
    "\n",
    "total_smiles = pred_tot.loc[list(range(20000)), 'SMILES']\n",
    "for smile in tqdm(total_smiles):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    fingerprint = AllChem.GetMorganFingerprint(mol,2)\n",
    "    total_fingerprint.append(fingerprint)\n",
    "\n",
    "\n",
    "for i in tqdm(range(20000)):\n",
    "    suggest_list.append(i)\n",
    "    #loop += 1\n",
    "    query_fingerprint = total_fingerprint[i]\n",
    "    if i >= 10:\n",
    "        target_fingerprints = total_fingerprint[0:i]\n",
    "        # need smiles to fingerprints code \n",
    "        scores = DataStructs.BulkTanimotoSimilarity(query_fingerprint, target_fingerprints)\n",
    "        total_similar_num = len(list(filter(lambda x: x > similar_value_threshold, scores)))\n",
    "        if total_similar_num > similar_num_threshold:\n",
    "            suggest_list.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 75/547906 [00:01<2:01:54, 74.90it/s]\n"
     ]
    }
   ],
   "source": [
    "if len(suggest_list) < 20000:\n",
    "    for i in tqdm(range(20000, pred_len)):\n",
    "        new_smile = pred_tot.loc[i, 'SMILES']\n",
    "        new_mol = Chem.MolFromSmiles(new_smile)\n",
    "        new_fingerprint = AllChem.GetMorganFingerprint(new_mol,2)\n",
    "        total_fingerprint.append(new_fingerprint)\n",
    "        suggest_list.append(i)\n",
    "        query_fingerprint = total_fingerprint[i]\n",
    "        target_fingerprints = total_fingerprint[0:i]\n",
    "        scores = DataStructs.BulkTanimotoSimilarity(query_fingerprint, target_fingerprints)\n",
    "        total_similar_num = len(list(filter(lambda x: x > similar_value_threshold, scores)))\n",
    "        if total_similar_num > similar_num_threshold:\n",
    "            suggest_list.pop()\n",
    "        if len(suggest_list) >= 20000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 3, 5, 7]\n",
    "b = a[0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95ead6bd2d45473fc34ca264613388bbb11a7ecfed696b93cdc96b68be756ec0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
